# Precog Quant Task 2026 - Algorithmic Trading Pipeline

**Author:** [Your Name]  
**Task:** Quantitative Trading Strategy Development  
**Institution:** Precog Research Group, IIIT

---

## ğŸ“‹ Project Overview

This repository contains an end-to-end algorithmic trading pipeline for a universe of anonymized stocks. The project transforms raw OHLCV price data into a systematic trading strategy that maximizes risk-adjusted returns.

### Task Completion Status

| Part | Task | Status |
|------|------|--------|
| 1 | Feature Engineering & Data Cleaning | â³ In Progress |
| 2 | Model Training & Strategy Formulation | â³ In Progress |
| 3 | Backtesting & Performance Analysis | â³ In Progress |
| 4 | Statistical Arbitrage Overlay | â³ In Progress |

---

## ğŸ—‚ï¸ Directory Structure

```
Precog Task/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ instructions/          # Task instructions
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original daily_prices.csv (NOT committed)
â”‚   â””â”€â”€ processed/             # Cleaned & engineered features (NOT committed)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_cleaning_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 02_model_training_strategy.ipynb
â”‚   â”œâ”€â”€ 03_backtesting_performance.ipynb
â”‚   â””â”€â”€ 04_statistical_arbitrage.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ cleaning.py        # Data quality checks & cleaning logic
â”‚   â”‚   â””â”€â”€ features.py        # Feature engineering functions
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ predictors.py      # Model architectures
â”‚   â”‚   â””â”€â”€ ensemble.py        # Ensemble methods
â”‚   â”œâ”€â”€ backtesting/
â”‚   â”‚   â”œâ”€â”€ engine.py          # Backtesting simulation engine
â”‚   â”‚   â””â”€â”€ metrics.py         # Performance metrics calculation
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ visualization.py   # Plotting & visualization helpers
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/               # Generated plots & visualizations
â”‚   â”œâ”€â”€ models/                # Saved model checkpoints
â”‚   â””â”€â”€ results/               # Performance logs & metrics
â”œâ”€â”€ tests/                     # Unit tests
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ .gitignore                # Git ignore rules
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- pip or conda package manager
- Kaggle account (for dataset download)

### Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd "Precog Task"
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Download the dataset from Kaggle:
   - Visit: https://www.kaggle.com/datasets/iamspace/precog-quant-task-2026
   - Download `daily_prices.csv`
   - Place it in `data/raw/`

### Running the Project

Execute notebooks in order:

```bash
# 1. Data Cleaning & Feature Engineering
jupyter notebook notebooks/01_data_cleaning_feature_engineering.ipynb

# 2. Model Training & Strategy Development
jupyter notebook notebooks/02_model_training_strategy.ipynb

# 3. Backtesting & Performance Analysis
jupyter notebook notebooks/03_backtesting_performance.ipynb

# 4. Statistical Arbitrage Analysis
jupyter notebook notebooks/04_statistical_arbitrage.ipynb
```

---

## ğŸ“Š Methodology

### Part 1: Feature Engineering & Data Cleaning

**Approach:**
- Data quality assessment (missing values, outliers, anomalies)
- Feature extraction capturing market dynamics:
  - Technical indicators (momentum, volatility, volume)
  - Statistical features (rolling statistics, z-scores)
  - [Add your specific approaches here]

**Key Decisions:**
- [Document your cleaning strategies]
- [Justify feature selection]

### Part 2: Model Training & Strategy Formulation

**Approach:**
- Prediction target: [Classification/Regression]
- Model architecture(s): [List models used]
- Ensemble methods: [If applicable]
- Signal generation logic: [How predictions â†’ trades]

**Key Decisions:**
- [Rationale for model choice]
- [Handling non-stationarity]
- [Risk management approach]

### Part 3: Backtesting & Performance Analysis

**Simulation Parameters:**
- Initial Capital: $1,000,000
- Transaction Costs: 10 bps per trade
- Universe: [Specify stocks traded]

**Performance Metrics:**
- Sharpe Ratio (annualized): [Value]
- Maximum Drawdown: [Value]
- Average Drawdown: [Value]
- Portfolio Turnover: [Value]
- Total Return: [Value]

**Analysis:**
- [Transaction cost impact]
- [Failure modes identified]
- [When/why strategy underperforms]

### Part 4: Statistical Arbitrage Overlay

**Approach:**
- Pair/group selection methodology: [Describe]
- Cointegration analysis: [Methods used]
- Lead-lag relationships: [Findings]

**Key Findings:**
- [Identified asset relationships]
- [Mathematical justification]
- [Integration with main strategy]

---

## ğŸ“ˆ Results Summary

### Out-of-Sample Performance (Test Period: [Start] - [End])

| Metric | Strategy | Benchmark | Difference |
|--------|----------|-----------|------------|
| Sharpe Ratio | [X.XX] | [X.XX] | [+/-X.XX] |
| Max Drawdown | [X.XX%] | [X.XX%] | [+/-X.XX%] |
| Total Return | [X.XX%] | [X.XX%] | [+/-X.XX%] |
| Turnover | [X.XX] | [X.XX] | [+/-X.XX] |

### Key Insights

1. **What Worked:**
   - [Insight 1]
   - [Insight 2]

2. **What Didn't Work:**
   - [Challenge 1]
   - [Challenge 2]

3. **Hypotheses for Future Improvement:**
   - [Hypothesis 1]
   - [Hypothesis 2]

---

## ğŸ“š References & Literature

1. [Key paper/resource 1]
2. [Key paper/resource 2]
3. [Key paper/resource 3]

---

## ğŸ”§ Dependencies

See [requirements.txt](requirements.txt) for full list. Key libraries:
- `pandas`, `numpy` - Data manipulation
- `scikit-learn` - Machine learning
- `matplotlib`, `seaborn` - Visualization
- `statsmodels` - Statistical analysis
- [Add others as used]

---

## ğŸ“ Notes & Future Work

- [Any limitations encountered]
- [Ideas for future extensions]
- [Computational constraints faced]

---

## ğŸ“§ Contact

For questions about this implementation:
- Email: [Your email]
- GitHub: [Your GitHub username]

---

**Disclaimer:** This project is for educational and research purposes as part of the Precog Research Group recruitment process.
